Let G be a group, and X a set with a G action, then X is a permutation set of G. A representation is $\rho:G \rightarrow GL(V)$ where V is usually a finite dimensional vector space. We can also cal it a G-module(whihc is more or less the module of the group ring R\[G\]).(see more in [[Basic Definitions of representation]])

some example:
1. for a cyclic group $C_n$, its representation $\rho(g)=\exp(\frac{2t\pi}{n})$, where t runs through 1,2,$\cdots$,n.(these are all its irreducible representations.)
2. for every group there is a trivial representation $\rho_0:G \rightarrow \{(1)\}$, which maps every element of $G$ to 1.
3. for a symetric group $S_n$, its natural per mutation group is the $n \times n$ permutation matrix.

Constructing G-module from G-set.
	Let G be a group and S be a G-set with $|S|< \infty$. We use it to construct a G-module. Let $S=\{s_1,s_2, \cdots, s_m\}$, and $V=\mathbb{C}[S]$ and vector space generated by elements of S. We let G act on V by gs=gs, where $s \in S ,g \in G$, the frist multiplication is the action on V,  and the second is the action on S. It is easy to check that it is indeed a G-module.

Let $G$ be a group, and let $G$ atc on itself by left multiplication, then the representation build from it is called the regular representation. Moreover, the groupring $\mathbb{C}[G]$ is the group algebra of $G$.
Using this, we can get the Caylay theorem(every finite group can be embeded into $S_n$ where $n=|G|$)
Example: Let $G \geq H$, then $\mathbb{C}[G/H]$ gets a G-module structure by $g(g_iH)=(gg_i)H$. Let $G=S_3$, $H=\{id,(12)\}$ compute the representation, how about $G=S_4$? what will happen when $G$ infanent while $H$ is finite?

Reducibility
Let $V$ be a complex permutation representation of $S_3$, it is clear that the subspace $u:=\{\lambda_1v_1+\lambda_2v_2+\lambda_3v_3:\lambda_1+\lambda_2+\lambda_3=0\}$ is also a $S_3$ module, with 
$$\rho(id)=\begin{pmatrix}1&0\\0&1\end{pmatrix},
\rho((12))=\begin{pmatrix}-1&1\\0&1\end{pmatrix},
\rho((123))=\begin{pmatrix}-1&-1\\1&0\end{pmatrix},
\rho((13))=\begin{pmatrix}0&-1\\-1&0\end{pmatrix}
$$
In fact, all group has the similiar property, and these group is called the irreducible representations. 

Definition: Let V be a G module, W a subspace of $V$ is called the submodule if G is stable under $W$. We are able to show that all G modules are projective (c.f. [[Projective module and injective module]]), hance we can always find another submodule $W^{\perp}$ such that $V=W \oplus W^{\perp}$,  so the concept of irreducible and indecomposable is the same in the case of finite group.
Example: for group $S_n$, its natural permutation representation has a subrepresentation $w:=\{(k,\cdots,k)\in \mathbb{C}^n\}$. Same thing happens for general groups.
Another example: $w:=\mathbb{C}[\sum\limits_{\sigma\in S_n}Sgn(\sigma)\sigma]$ becomes the sign module for $S_n$ in $V$.
Definition: A representation of a group $G$ is irreducible if and only if there is not subrepresentation of $V$ i.e. one can find a basis for $V$ such that for every $g\in G$, $$\rho(g)=\begin{pmatrix}A(g)&B(g)\\0&C(g)\end{pmatrix}$$where $A(g)$ is a square matrix and 0 is nonempty.

example: Find a basis for $\mathbb{C}[1,2,3]$ in the above block form: first notice that $W:=\mathbb{C}[1+2+3]$, hence we get the basis extend from $1+2+3$, for example, $1+2+3,\,2,\,3$, then$$\rho(id)=\begin{pmatrix}1&0&0\\0&1&0\\0&0&1\end{pmatrix},
\rho((12))=\begin{pmatrix}1&1&0\\0&-1&0\\0&-1&1\end{pmatrix},
\rho((13))=\begin{pmatrix}1&0&1\\0&1&-1\\0&0&-1\end{pmatrix},
$$
$$\rho((23))=\begin{pmatrix}1&0&0\\0&0&1\\0&1&0\end{pmatrix},\rho((123))=\begin{pmatrix}1&0&1\\0&0&-1\\0&1&-1\end{pmatrix},
\rho((132))=\begin{pmatrix}1&1&0\\0&-1&1\\0&-1&0\end{pmatrix}$$

recall: Let $V$ be a vector space, and $I \subset V$ be linearly independent, and $I \subset S \subset V$ spans $V$, then there is a bsis $\beta \in V$ such that $I \subset \beta \subset S$. (easy to proof using zorn's lemma)

Thus we can say that $V \oplus W$ is also a representation of $G$, and we can find a basis of it such that $\rho(g)$ broke up into two parts.

The converse is more interesting: Let $V$ be a linear representation, and $W \subset V$, we hope that there is always a $W^{\perp}$ such that $W \oplus W^\perp =V$. We say that $V$ is indecomposable is there does not exists $U,W \in V$ such that $V=U \oplus W$.
This is in fact not true in general:
1. If G is infanent, then is is not true, for example G consists of all $2\times2$ complex upper triangle matrix whose value on the diagon is all 1.  It can obviously act on $\mathbb{C}^2$, and there is a subspace $W:=\{(x,0)^T\}$, but its compliment is not stable under G.

Luckly, for finite groups this property usually exists(i.e. every indecomposable representation is irreducible representation)

Theorem(Maochke's) Let G be a finite group, and let V be a G-module, over a field in which $|G| \neq 0$. Let $U$ be a proper G-submodule if V, then there exists another submodule W such that $V =U \oplus W$.

Proof: Let $V=U \oplus Z$, where Z need not to be a G-module, then for $g \in G,z\in Z$, we have $gz=\tau_gz+\sigma_gz$, then we have $\sigma_1z=z,\tau_1z=0$ for all $z \in Z$. Whence $\sigma_{g^{-1}} \sigma_g z=z$ for all $g \in G,z \in Z$. Moreover we have $hgz=h\tau_gz+\tau_h\sigma_gz+\sigma_h\sigma_gz$, hence $\sigma_{hg}z=\sigma_hz\sigma_gz$, specififally $\sigma_{g^{-1}}=\sigma_g^-1$. Then $\sigma_{hg}^{-1}z=\sigma_{(hg)^{-1}}(\sigma_hz)=\sigma_{g^{-1}}\sigma_{h^{-1}}\sigma_{h}z=\sigma_{g^{-1}}z$, we alos have $\tau_{hg}(\sigma_{g^{-1}})=h\tau_g\sigma_{g^{-1}}z+\tau_{h}z$, hence $\tau_{hg}\sigma_{hg}^{-1}\sigma_hz=h\tau_g\sigma_{g^{-1}}z+\tau_hz$, summing up, we get $\sum\limits_{g \in G} \tau_{hg}(\sigma_{(hg)^{-1}}\sigma_hz)=h \sum\limits_{g \in G} \tau_g\sigma_{g^{-1}}z+|G|\tau_hz$, let $\eta = \frac{1}{|G|} \sum\limits_{g \in G} \tau_g(\sigma_{g^{-1}}z)$, so we have $\eta(\sigma_hz)=h(\eta z)+\tau_hz$. Let $W:=(\eta+id)Z$, then for $h \in G,w \in W$, we have $hw=hz+h(\eta z)=hz+\eta(\sigma_hz)-\tau_hz=\sigma_hz+\eta(\sigma_hz) \in Z$, hence $W$ is stable under G, it is easy to check that $W$ is a compliment of $U$ #
(simpler proof: Let $p$ be the projection $V \rightarrow U$, take $p_0=\frac{1}{|G|}\sum\rho_gp\rho_g^{-1}$, then $p_0$ acts on $U$ as $id$, and $0$ on the compliment $Z$ of $U$, moreover, it is easy to see that $p_0$ commute with $\rho_g$, so $\rho_gZ \in Z$.)

**Theorem**(Maschke's:finite dimensional over $\mathbb{C}$): Let $G$ be a finite group, $V$ a finite dim $G-group/\mathbb{C}$, ans $U$ be a proper $G-submodule$, then there exists a $G-submodule$ $W$ of $V$ s.t. $V=U \oplus W$.
Proof: Define an inner product on $V$, recall that a function on $(,):V \times V \rightarrow \mathbb{C}$ is an complex inner product (c.f.[[高等代数2 note]]). We define an inner product over $V$ by taking a basis $v_1, \cdots, v_n$, and $(v_i,v_j)=\delta_{ij}$ and extend linearly. We use it to get an $G-invariant$ inner product by $u*v=\sum (gu,gv)$. Take $W:=U^{\perp}$, we have $V=U\oplus W$, and $u*gv=g^{-1}u*v=0$, hence $gv \in W$.
(Using the language of matrix, what we have is that for a matrix representation, we can always find a $T$ such that $T\rho(g)T^{-1}$ can be broke up in to blocks of irreducible representations)

**Example**: Construct the compliment of $\mathbb{C}[1+2+3]$ in $\mathbb{C}[1,2,3]$ as an representation of $S_3$, using the inner product $\langle a1+b2+c3, x1+y2+z3 \rangle:=a\bar{x}+b\bar{y}+c\bar{z}$, then we get $\mathbb{C}^\perp=\{v=a1+b2+c3:a+b+c=0\}$.

To learn that whether two irreducible representations are isomorphic, we use the [[Schur's lemma]].

Example: Let $\lambda=(\lambda_1, \cdots, \lambda_l)$ be a partitions of n (c.f. [[representation of symmetric group]]), consider the young subgroup $H= \prod S_{\{i_k, \cdots, i_{k+1}\}}$ , has a natural action of $S_n$ on it, extending lineardly, it can be seen as an $S_n$ module.

**Theorem**: Let $V$ and $W$ be $G-modules$ and let $f:V \rightarrow W$, be a G-homomorphism.
$kerf:=\{v \in V:f(v)=0\}$ is a G-submodule if $V$. If $imf:=\{f(v):v \in V\}$, then it is a submodule of $W$. Furthermore, there is an isomorphism $\theta: V/kerf \rightarrow imf$ sending $v+ker(f) \mapsto f(v)$. 
Proof: clear.

Lemma([[Schur's lemma]] V1):Let $U,V$ be irreducible representation of $G$, and $\phi:U \rightarrow V$ is a G-homomorphism. Then $\phi$ is either an isomorphism or an zero map.
Proof:note that $ker(\phi) \leq_G U$, so $ker(\phi)$ is either $\{0\}$ or $U$, the same argument using on $V$, then we are done.

Lemma([[Schur's lemma]] V2): Let $R:G \rightarrow GL_n$ and $S:G \rightarrow GL_n$ be irreducible $\mathbb{C}-matrix$ representations of $G$, ans let $X$ be an $n \times m$ which interwines $R$ ans $S$, THen either $X=0$ or $X$ is invertable and $n=m$.

Lemma([[Schur's lemma]] V3): Let $R:G \rightarrow GL_n$ can be irreducible $\mathbb{C}-matrix$ representation of $G$, ans suppose the that $X$ an $n \times n$ matrix, s.t. $R(g)X=XR(g),\forall g \in G$, then $X=\lambda Id$ for some $\lambda \in \mathbb{C}$.
Proof: Let $\lambda$ be an eigenvalue of $X$, then $det(X-\lambda Id)=0$, and $X-\lambda Id$ commute with $R(g)$, so $X-\lambda Id=0$
*Remark:* In the V3, the field is not necessarily $\mathbb{C}$, but should be algebraicly closed.


# characters
Now we consider the character of representations

Lemma: Let $G$ be a finite group, and let $R$ ans $S$ be $\mathbb{C}-matrix$ representations of $G$ with degree $n,m$. If $X$ is any $n \times m$ matrix then $Y:=\sum\limits_{g \in G}R(g)XS(g^{-1})$ interwines $R,S$.
Proof:easy.

Suppose now that $R^{(1)}, \cdots, R^{(S)}$ are irreducible $\mathbb{C}-matrix$ representations of finite group $G$, of degree $d_1, \cdots, d_S$. Further, assume that $R^(i) \not\simeq R^(j),i \neq j$, is pairwise inequivalent. 
Choose $k,l$ arbitraily, and for $1 \leq m \leq d_k,1 \leq n \leq d_l$ Let $X_{m,n}^{k,l}$ be that $d_k \times d_l$ matrix where $(t,u)$ is 0 unless $t=u$ in which case it is 1. Then $Y^{k,l}_{m,n}:=\frac{1}{|G|} \sum\limits_{g \in G} R^{(k)}(g)X^{k,l}_{m,n}R^{(l)}(g^{-1})$. Using [[Schur's lemma]], we get that $Y^{k,l}_{m,n}=0$ if $k \neq l$, and $Y^{k,k}_{m,n}$ must be a scalar of $I_{d_k}$. So $(Y^{k,l}_{m,n})_{pq}=\lambda(k,m,n)\delta_{pq}\delta_{kl}$, but using the definition, one get that $(Y^{k,l}_{m,n})_pq=\frac{1}{|G|}\sum\limits_{g\in G}R^{(k)}_{pm}(g)R^{(l)}_{nq}(g^{-1})$. Meanwhile, set $X_{q,p}^{k,l}$ to be that $d_l \times d_k$ matrix where $(t,u)$ is $\delta_{tq}\delta_{up}$, set $Y^{l,k}_{q,p}:=\frac{1}{|G|}\sum\limits_{g \in G} R^{(l)}(g)X^{l,k}_{q,p}R^{(k)}(g^{-1})$, then one get $\lambda(l,q,p)\delta_{nm}\delta_{kl}=(Y^{l,k}_{q,p})_{n,m}=\frac{1}{|G|}\sum\limits_{g \in G}R^{(l)}_{nq}(g)R^{(k)}_{pm}(g^{-1})$. Hence $\lambda(l,q,p)\delta_{nm}\delta_{kl}=\lambda(k,m,n)\delta_{pq}\delta_{kl}$. One immediatly notice that $\lambda(k,n,n)=\lambda(l,p,p)=\mu(k)$, depending only on k, so $\lambda(k,m,n)=\mu_kf_{mn}$. Thus $\frac{1}{|G|}\sum\limits_{g \in G} R^{(l)}(g)X^{l,k}_{q,p}R^{(k)}(g^{-1})=\mu_k\delta_{nm}\delta_{pq}\delta_{kl}$. Putting $l=k,m=n$ and summing over all valumes of $n$ from 1 to $d_k$, then $\frac{1}{|G|}\sum\limits_{g \in G} \sum\limits_{n=1}^{d_k}R^{(k)}_{pn}(g)R^{(k)}_{nq}(g^{-1})=\mu_kd_k\delta_{pq}$, but $R^{(k)}(g)R^{(k)}(g^{-1})=Id_k$, so $\mu_k=d_k^{-1}$. Now using this conclusion, one get $\frac{1}{|G|}\sum\limits_{g \in G}R^{(l)}_{nq}(g)R^{(k)}_{pm}(g^{-1})=d_k^{-1}\delta_{nm}\delta_{kl}\delta_{pq}$. 
(actually, there is a much faster rutine: note that $\chi_{V^*}(g)=\overline{\chi_V(g)}$ and $\chi_{V \otimes W}(g)=\chi_{V}(g)\chi_W(g)$, then one get that $\langle \chi_V,\chi_W \rangle = \frac{1}{|G|}\sum\limits_{g \in G}\chi_V(g)\overline{\chi_W(g)}=\frac{1}{|G|}\sum\limits_{g \in G}\chi_{V \otimes W^*}(g)=Tr|_{V \otimes W^*}(P)$, where $P=\frac{1}{|G|}\sum\limits_{g \in G} g \in \mathbb{C}[G]$, hence $\langle \chi_V, \chi_W \rangle =dimHom(\mathbb{C},V \otimes W^*)=dimHom(V,W)$.)

Definition: a matrix $M$ with elements in $\mathbb{C}$ is unitraty if its matrix form is unitraty (c.f.[[高等代数2 note]]). 

**Proporsition**:
Suppose that $G$ is a finite group, and $R:G \rightarrow GL_d(\mathbb{C})$, is a $\mathbb{C}-matrix$ representation of $G$, then there is a invertable $T$ s.t. $TR(g)T^{-1}$ is unitraty for all $g \in G$.
*Proof*:
$V:=\mathbb{C}^d$ consisting of all d-component vector. $V$ is a $G-module$ via $gv=R(g)v$. $V$ is an inner product space relate to the std. inner product $\cdot$ to the std. basis $(\mu_1, \cdots,\mu_d)^T \cdot (\lambda_1,\cdots,\lambda_d)^T=\sum_{i=1}^{d}\overline{\lambda_i}\mu_i$. From this, we get an $G-invariant$ inner product: $v * u=\sum_{g \in G}(gv) \cdot (gu)$. Choose a basis $\{v_1,\cdots,v_d\}$ and $S$ be the matrix representations under that basis, then $gv_i=\sum_j(S(g))_{ji}v_j$, and $R,S$ are equivalent, we claim that $S$ is unitraty. Indeed, $\forall j,k$ $\delta_{jk}=v_j*v_k=(gv_j)*(gv_k)=(\sum_i(S(g))_{ij}v_i)*(\sum_i(S(g))_{ik}v_i)=\sum_i\overline{(S(g))_{ji}}S((g))_{ik}$, hence $S(g)^{\dagger}S(g)=I$, is unitraty. 

Thus we may assume that all $R^{(i)}$ are unitraty, therefore $\forall l,g,\ R^{(l)}(g^{-1})=(R^{(l)}(g))^{-1}=(R^{(l)}(g))^\dagger$, using the formula $\frac{1}{|G|}\sum\limits_{g \in G}R^{(l)}_{nq}(g)R^{(k)}_{pm}(g^{-1})=d_k^{-1}\delta_{nm}\delta_{kl}\delta_{pq}$, we are going to show $\sum_kd_k^2=|G|$. Taking $X_{kpm}:=\{R^{(k)}_{pm}(g_1),\cdots,R^{(k)}_{pm}(g_{|G|})\}$. One immediatly know that the inner product $X_{kpm}$ and $X_{kqn}$ if $k=l,p=q,m=n$, in which case is equal to $\frac{|G|}{d_k}$. These vectors are linearly independent, because they are nonzero and pairwise orthogonal. So thay span a span s space of dimension $\sum_kd_k^2$, contained in te space of $|G|$ dimensional vector space, so $\sum_{k=1}^sd_k^2 \leq |G|$, hance $s \leq |G|$. 

**Definition**:
The *Coordinat space* of a representation.
We consider all the $\mathbb{C}$ valued function on the set $\{1, \cdots,n\}$ forms a victor space $V_S$. Let $S:G \rightarrow GL_d(\mathbb{C})$ be a $\mathbb{C}-matrix$ representations for the group $G$ the $(i,j)$ coordinat fuction $S_{ij}:S \rightarrow \mathbb{C}$ is defined by $S_{ij}(g):=$ the $(i,j)$ entry of $S(g)$. The coordinat space of $S$ is the space of $S$ is the submodule of $V_G$ spanned by the coordinat fuction of $S$. $V_{G}$ is the $|G|-dimensional$ space over $\mathbb{C}$ containing all $\mathbb{C}-valued$ functions on $G$.

**Proporsition**:
Equivalent representations have the same coordinat space.
*Proof*:
Let $R$ and $S$ be equivalent representations of degree $n$. $\exists$ an invertable $T$ such that $T^{-1}R(g)T=S(g),\forall g \in G$. Then for all $g \in G$, $S_{ij}(g)=(T^{-1}R(g)T)_{ij}=\sum_k\sum_l(T^{-1})_{il}R_{lk}(g)T_{kj}$, so $S_{ij}=\sum_{k,l}((T^{-1})_{il}T_{kj})R_{lk}$, hence the coordinat space of $S$ is contained in the coordinat space of $R$, same argument shows the other way is true as well.

**Proporsition**:
THe coordinat sapce of the diagonal sum of the two representations $R$ and $S$ is the vector space sum of the coordinat space of the coordinat space of $R$ and $S$.

Maochke's theorem tells us that every $\mathbb{C}$-representation of a finite group id equivalent to a diagonal sum of irreducible representations. Then if we fix a full set of $PIIR$ $R^{(1)}, \cdots,R^{(s)}$ then its coordinat space if any representation is contained in the sum of coordinat sace of the $R^{(k)}$'s.

**Proporsition**:
The coordinat space of the regular representation of a finite group $G$ is equal to $V_G$, the space of all $\mathbb{C}-valued$ function defined on $\mathbb{C}$.
*Proof*:
The coordinat space of the regular representation is certainly contained in $V_G$. Let $g_1, \cdots,g_n$ be the complete list of of elements in $G$. The degree of the regular representation is $n$. Let $h \in G$ be arbitrary. If the $j$-th column of $R(h)$ if $(\lambda_1, \cdots,\lambda_n)^T$, then $hg_j=\sum_i\lambda_ig_i$, and so $\lambda_i=1$ if $hg_j=g_i$ and $\lambda_i=0$ otherwise. Then $R_{ij}$ can be identified with the n-component vector $(R_{ij}(g),\cdots,R_{ij}(g_n))$, since any $g_1,\cdots,g_n$, there is a unique $g_k$ such that $g_kg_j=g_i$, it follows that $R_{ij}$ can be identified with the n-component row vector with only the k-th component lying 1 and all other lying 0. Fix $j=1$. Let $g_{l_1}$ be the unique element in $G$ with $g_{l_1}g_1=g_1$. Then $R_{11}$ can be indentified with the row vector $(0,\cdots,0,1,0,\cdots,0)$, where 1 is at the $l_1$-th column. Next let $g_{l_2} \in G$ be the unique element with $g_{l_2}g_1=g_2$, in particular, $g_{l_1} \neq g_{l_2}$, and $R_{21}$ can be identified with $(0,\cdots,0,1,0,\cdots,0)$ where 1 is at the $l_2$-th column. Similiarly, for $i=3,\cdots,n$, and we have distict $l_1, \cdots,l_n$ with $R_{k1}$ being identified with $(0,\cdots,0,1,0,\cdots,0)$ with 1 on the $l_k$-th position. Let $f \in V_G$ be arbitrary. Then $f$ can be identified with $f(g_1),\cdots,f(g_n)$, so $f=\sum_if(g_{l_i})R_{i1}$, hence $V_G$ is contained in the coordinat space of $R$ the regular representation of $G$. The coordinat space of the irreducible representation $R^{(k)}$ is spanned by the $d_k^2$ coordinat function $R_{pm}^{(k)}$, $p,m \in \{1, \cdots,d_k\}$. The sum of the coordinat spaces of $R^{(1)}, \cdots,R^{(s)}$ (being a full set of $PIIR$) is spanned by the coordinat function $R^{(k)}_{pm}$, set $L:=\{R^{(k)}_{pm}:1 \leq k \leq s, \  p,m \in \{1, \cdots,d_k\}\}$. But the sum of coordinat space must equal to $V_G$, since it nust contained the coordinat space of the regular representation, whence equality, i.e. $|G|=dimV_G$, $|L|=\sum_{k}d_k^2$.

Let $V_G$ be the set of all $\mathbb{C}$-valued functions defined over a group $G$. It is then a $|G|$-dimensional vector spacce. For all $g \in G$, set $f_g(h)=1$ if $gh=1$, and 0 if not. One immediatly note that $f_g$ forms a basis of $V_G$.
Easy to check that $V_G$ is a right $G-module$ by $gf(h)=f(hg)$.

**Definition**:
A function $f \in V_G$ is called a class function if it takes to same value on elements in the same conjugacy class, i.e.$f(h)=f(ghg^{-1})$ for all $g,h \in G$. Moreover, it is equivalent to $gf=fg$ for all $g \in G,f \in V_G$.

**Proporsition**:
The set of all class function is $V_G$ is a vector subspace of $V_G$ of dimension equal to # of conjugacy classes of $G$.
*Proof*:
The set of all class fuction is obviously a vector space of $V_G$.
Let $c_1, \cdots,c_t$ be all the conjugacy classes of $G$ and for each $i \in \{1, \cdots,t\}$ let $F_i$ eb tha fuction given by $F_i:=\sum_{g \in c_i}f_{y^{-1}}$. Then $F_i(g)$ is 1 if $g \in c_i$ and 0 if not. Now every class fuction $f=\sum_{i=1}^t \lambda_iF_i$. clearly $F_i$ are linearly indepent. Thus $F_i$ are indeed a basis of class functions.

**Definition**:
Let $(V,\rho)$ be a linear representation of $G$, then the character $\chi:G \rightarrow \mathbb{C}$ of $V$ is the trace $\chi(g)=Tr(\rho_g)$.

Obviously, $\chi$ is a class function, and using the fact that the coordinat function are linearly independent, one get $\chi_i$ are linearly independent.

**Proporsition**:
If $R^{(1)}, \cdots,R^{(s)}$ form a full set of $PIIRs$ with $\chi^{(1)}, \cdots,\chi^{(s)}$ being the corresponding characters then they form a basis of the subspace of all class function (c.f.[[Property of the character table]])
*Proof*:
$\chi^{(1)},\cdots,\chi^{(s)}$ are linearly independent so we only need to check that they spanned the subspace. Let $f \in V_G$ be a class function. For irreducible representation $R^{(h)}$, define $M_h:=\sum_{g \in G}\overline{f(g)}R^{(h)}(g)$, then it is commutative with $R^{(h)}$, i.e.$(R^{(h)}(x))^{-1}M_hR^{(h)}(x)=M_h$. Hence (using [[Schur's lemma]]) $\sum_{g \in G}\overline{f(g)}(R_{ij}^{(h)}(g))=\lambda_h\delta_{ij}$. For all $f_1,f_2 \in G$, let $(f_1,f_2)=\frac{1}{|G|}\sum_g\overline{f_1(g)}f_2(g)$, then $(,)$ forms a G-invariant inner product space on $V_G$. Recall $\frac{1}{|G|}\sum_gR^{(k)}_{pm}(g)\overline{R^{(l)}_{qn}(g)}=d^{-1}_k\delta_{pq}\delta_{mn}\delta{kl}$. Note that $R^{(k)}_{pm}$ spanned $V_G$, so for all $f \in V_G$, $f= \sum_{k,p,m}\mu_{kpm}R^{(k)}$, hence $(R^{(h)}_{ij},f)=\sum_{k,p,m} \overline{\mu_{kpm}} d^{-1}_n \delta_{hk} \delta_{ip} \delta_{jm}$. Hece $M_{hij}=\frac{d_h\overline{\lambda_n}\delta_{ij}}{|G|}$, so $f=\frac{1}{|G|}\sum_hd_n\overline{\lambda_n}\chi^{(h)}$.#

Moreover, the equation $\frac{1}{|G|}\sum_gR^{(k)}_{pm}(g)\overline{R^{(l)}_{qn}(g)}=d^{-1}_k\delta_{pq}\delta_{mn}\delta{kl}$ shows that $(\chi_k,\chi_l)=\delta_{kl}$.
Using the fact that every representation of finite group is unitraty, then $\chi(g^{-1})=\overline{\chi(g)}$. so we get :
**Theorem**:
If $\chi$ and $\phi$ are character for irreducible representation $R,S$, of finite group $G$, then $R,S$ are equivalent if $\chi=\phi$.
and:
**Theorem**:
If $\chi,\phi$ are characters of two irreducible representations of finite group $G$, then $(\chi,\phi):=\frac{1}{|G|}\sum_{g \in G}\chi(g)\phi(g^{-1})=\begin{cases}1 &\text{ if } \chi=\phi\\0 &\text{ if not}\end{cases}$. Using this, one find a way to compute whether two representation are equivalent.

Note that $\chi(g)=Tr|_V(g)$, is the sum of all eigenvalues of $\rho_g$, one alos have $\rho_{g^{-1}}=\rho_g^{-1}$. Note that $|G|<\infty$, then there is $n \in \mathbb{Z}$ such that $g^n=1$, so $\rho_g^n=id$, so all eigenvalues of $\rho_g$ are n-th root of unity. So one get that the $\chi(g^{-1})=\overline{\chi(g)}$. 

Now we get the orthogonality relation between characters. Take $V_1,\cdots,V_s$ be the set of all irreducible representations different up to isomorphism. Let $\chi_1, \cdots, \chi_s$ be their characters, then $(\chi_i,\chi_j)=\delta_{ij}$. So they form an orthogonal basis for the vector space of class functions, in particular $s$ is euqal to the number of conjugacy classes of $G$. The character table has a row for each irreducible representations, and one column for each conjugacy classes, the entry are $\chi_i(g)$ if $g$ is in the j-th conjugacy classes. One immediatly know that $|\chi_k|<d_k$ where $d_k=dim(V_k)$.

**Example**:
$$
\begin{array}{c|lcr} 
& g_1 & g_2 & g_3 & g_4 & g_5 & g_6\\ 
\hline 
\chi_1 & 1 & 1 & 1 & 1 & 1 &1 \\ 
\chi_2 & 3 & -1 & 1 & 0 & \frac{-1+i\sqrt{7}}{2} & \frac{-1-i\sqrt{7}}{2} \\ 
\chi_3 & 3 & -1 & 1 & 0 & \frac{-1-i\sqrt{7}}{2} & \frac{-1+i\sqrt{7}}{2}\\
\chi_4 & 6 & 2 & 0 & 0 & -1 & -1\\
\chi_5 & 7 & -1 & -1 & 1 & 0 & 0\\
\chi_6 & 8 & 0 & 0 & -1 & 1 & 1
\end{array}
$$
$|G|=1^2+3^2+3^2+6^2+7^2+8^2=168$.

Regarding the character table as the $s \times s$ matrix with the $(k,j)$-entry $\chi_k(g_j)$. Let $U$ be the $s \times s$ matrix whose $(j,l)$-entry is $\frac{1}{|G|}h_j\overline{\chi_j(g_j)}$, then $(TU)_{k,l}=\frac{1}{|G|}\sum_jh_j\chi_k(g_j)\overline{\chi_l(g_j)}=\delta_{kl}$, ($h_j$ is the number of elements in the conjugacy classes of $g_j$)

**Definition**:
The center of a group $G$ denoted by $Z(G)$ is the set of all $a \in G$ that commute with all elements of $G$, i.e. $Z(G):=\{a \in G:ag=ga,\,\forall g \in G\}$. And $C_G(a):=\{g \in G:ag=ga\}$ is the set of all $g \in G$ that commute with $a$.

**Proporsition**:
If $a \in G$, then the number of elements in the conjugacy classes containing a is equal to $[G:C_G(a)]$. 

Using the proporsition above, one get $\sum_j\chi_l(g_j)\overline{\chi_k(g_j)}=\delta_{jk}|C_G(g_j)|$.

**Expressing the regular representation in terms of irreducible representations**
Let $G$ be a finite group of order $n$, and let $G={g_1,\cdots,g_n}$. Let $R:G \rightarrow GL_n(V)$ be the matrix version of the regular representation.
For $g \in G$, action on $\mathbb{C}[G]$, $gg_j=\sum_k\lambda_kg_k$ with only one $\lambda_k=1$ in which case $gg_j=g_k$. Then $R_{ij}(g)=\begin{cases}1 \text{ iff } gg_j=g_i\\0 \text{ otherwise}\end{cases}$. In particular, $\forall i$, the (i,i) entery of $R(g)$ if 1 iff $g$ is the identity. So $\chi(g)=\begin{cases}n=|G|&\text{ if }g=1_G\\0&\text{ otherwise}\end{cases}$, now for each of the irreducible character $\chi_i$, $(\chi,\chi_i)=d_i$. 
Recall that we have proved that the irreducible characters forms a basis for the subspace of all class functions in $V_G$. Thus $\chi$ can be uniquly expressed in the form of $\chi=\sum_{i}m_i\chi_i$, then $m_l=(\chi,\chi_l)=d_l$.

Let $L$ be a subgroup of $G$, and let $x_1,\cdots,x_n$ be a complete set of left coset of $L$ in $G$. For each $g \in G$, and each $j \in \{1,\cdots,n\}$, $gx_jL=x_iL$. Thus $G$ acts on $(x_i)_i$ as left multiplication. This gives a permutation representation of $G$. 
Now let $R$ be a  matrix representation of $L$ of degree $d$. for each $j \in \{1,\cdots,n\}$, there is a unique $i$ such that $x_i^{-1}gx_jL=L$. Let $R^G(g)$ be the $nd \times nd$ whihc is an $n \times n$ array of $d \times d$ blocks, where the $ij$ block is zero if $x_i^{-1}gx_j\not\in L$.(i.e. simply the tensor product $\mathbb{C}[G] \otimes_{\mathbb{C}[L]} R$)
If we let $\dot{R}(g)=\begin{cases}0_{d \times d} &\text{ If } g \not\in L\\ R(g) &\text{ if } g \in L\end{cases}$, then 
$$
R^G(g)=\begin{pmatrix}\dot{R}(x_1^{-1}gx_1)&\dot{R}(x_1^{-1}gx_2) &\cdots &\dot{R}(x_1^{-1}gx_n)\\ \dot{R}(x_2^{-1}gx_1)&\dot{R}(x_2^{-1}gx_2)&\cdots&\dot{R}(x_2^{-1}gx_n)\\ \vdots&&\ddots\\ \dot{R}(x_n^{-1}gx_1)&\dot{R}(x_n^{-1}gx_2)&\cdots&\dot{R}(x_n^{-1}gx_n)\end{pmatrix}
$$

**Definition**:(c.f.[[Basic Definitions of representation]])
$L \subseteq G$ and fix $x_1,\cdots,x_n$ for the left coset of $L$, i.e. $G=\bigcup x_iL$. If $R$ id a representation of $L$, then the corresponding induced representation $Ind_L^G(R)$. If $\chi$ is a character for $R$, then $Ind_L^G(\chi)$ be its character for $Ind_L^G(R)$. 
Then $Ind_L^G(\chi)(g)=\frac{1}{|L|}\sum\limits_{x^{-1}gx \in L}\chi(x^{-1}gx)$.

Let $\{h_1,\cdots,h_l\}$ be a complete set of right coset representatives of $C_G(g)$ in $G$. If $x \in C_G(g)h_i$ $\Rightarrow$ $x=yh_i$, $y \in C_G(g)$. Then $x^{-1}gx=h_i^{-1}gh_i$, so $Ind_L^G(\chi)(g)=\frac{1}{|G|}|C_G(g)|\sum_{l \in \mathcal{L}}\chi(l)$ where $\mathcal{L}=g^{G} \cap L$. 
If $l_1,\cdots,l_m$ are representatives of these conjugacy classes $Ind_L^G(g)=\frac{|C_G(g)|}{|L|}\sum_{i=1}^mq_i \chi(l_i)$, where $q_i$ i the member of elements in the $L$-conjugacy classes of $l_i$, so $q_i=\frac{|L|}{|C_G(g)|}$. Thus $Ind_L^G(\chi)(g)=\frac{|G|}{|L|}\sum_{i=1}^{m}\frac{q_i}{h}\chi(l_i)$.

**Definition**:
Let $L \leq G$ an let $R$ be a representation if $G$. The restriction of $R$ to $L$ denoted by $Res_L^G(h)=R(h),\forall h \in L$. If $R$ has a character $\chi$, then denote the character by $Res_L^G(\chi)(h)=\chi(h),\forall h \in L$. 
*Question*:if $L \leq G$ and $R$ is an irreducible representation for $G$, is $Res_L^GR$ irreducible?

Let $L \leq G$, and $\{x_1,\cdots,x_n\}$ be a representatives of cosets for L in G. Let $R$ be a representation for $L$ with corresponding character $\chi$. Let $Ind_L^GR$ be the induced representation from $L$ to $R$ with corresponding character $Ind\chi$. Recall that $\forall g \in G$, $\dot{\chi}(g):=\begin{cases}\chi(g)&\text{ if }g \in L\\0&\text{ if } g \not\in L\end{cases}$. Then $Ind\chi(x_i^{-1}gx_i)=\dot{\chi}(h^{-1}x_i^{-1}gx_ih),\forall h \in L$. So $Ind\chi(g)=\frac{1}{|L|}\sum_i\sum_{h \in L}\dot{\chi}(h^{-1}x_i^{-1}gx_ih)$, but as $h$  runs over $L$, and $x_i$'s run over the the representatives of cosets, the product $x_ih's$ runs over the whole of $G$ ecaxtly once.
$Ind\chi(g)=\frac{1}{|L|}\sum_{x \in G}\dot{\chi}(x^{-1}gx)$.

**Theorem**:(Forbenious Reciprocity)
Let $l \leq G$, and let $\epsilon$ and $\chi$ be characters of $L$ and $G$ respectively. Then $(Ind\epsilon,\chi)_G=(\epsilon,Res\chi)_L$.
*Proof*:
$$
(Ind\epsilon,\chi)_G=\frac{1}{|G||L|}\sum_{g \in G}\sum_{x \in G}\dot{\epsilon}(x^{-1}gx)\chi(g^{-1})=\frac{1}{|L|}\sum_{x \in G}\dot{\epsilon}(y)\chi(y^{-1})=(\epsilon,Res\chi)_L
$$

**Definition**:
Let $F$ be a field. An $F$-algebra is a vector space over $F$ equipped with an operation $A\times A \rightarrow A$ wich is $F$-bilinear. Then for a vector space $A$ over $F$ will be an $F$-algebra. The product must be a vector multiplication.
(Note:the product need not be associative)
*Example*:
$\mathbb{R}^3$ with usual cross product is an $\mathbb{R}$-algebra. (also known as lie algebra)

Suppose $v_1,\cdots,v_n$ be basis for $A$, and $v_iv_j=\sum_{k}\alpha_{ijk}v_k$, we say that $\alpha_{ijk}$ be the *structral constant* of $A$ for a given basis. Let $u=\sum_{i}\lambda_iv_i,v=\sum_{j}\mu_jv_j$, then $uv=\sum_k(\lambda_i\mu_j\alpha_{ijk})v_k$. Conversely, if we choose $\alpha_{ijk}$ arbitrarily. 

Clearly, $k[G]$ is an associative algebra with identity.

**Definition**:
Let $A$ be an $F$-algebra. A matrix representation of $A$ is a algebra homomorphism $A \rightarrow M_{n \times n}(F)$. 

**Wesserburn's theorem**(c.f.[[Block theory]])
The complex group algebra $\mathbb{C}[G]$ of finite group $G$ is isomorphic to $A$, a direct sum of full matrix algebra.
*Proof*:
Let $R_1,\cdots,R_n$ be all irreducible representations of $G$, and $A=\bigoplus_iR_i$ be their direct sum (in the form of matrix). Then $\mathbb{C}[G] \rightarrow A$ is natural. Note that the dimension on both side are the same, so we only need to check that is is surjective.
Choose $k \in \{1,\cdots,n\}$ and $i,j \in\{1,\cdots,d_k\}$, and let $\alpha:=\frac{1}{|G|}\sum_{g \in G}\overline{R^{(k)}_{ij}(g)}g \in \mathbb{C}[G]$. Then the $(p,q)$ element of $R_l(\alpha)$ is $d_l^{-1}\delta{lk}\delta{pi}\delta{qi}$, which is zero unless $k=l,(p,q)=(i,j)$. Hence $\phi(\alpha)=(0,\cdots,0,\delta_{ij},0,\cdots,0)$. So it is surjective.

---
In the following part, algebra will be assumed to have a unit, unless stated otherwise.

**Definition**:
An $F$-algebra homomorphism is a map $A \rightarrow B$ preserving the structure of $F$-algebra (sending $1_A \mapsto 1_B$). In particular, $End_F(V)$ is an $F$-algebra, so the $A$-module $V$ has an natrual map to $A \rightarrow End_F(V)$. In particular, Let $A=F[G]$, then the module of $A$ is the representation of $G$.

**Definition**:
Let $A$ be an $F$-algebra, then the regular module of $A$ is $A \times A \rightarrow A$, sending $(a,b) \rightarrow ab$.

Using the language of algebra, one can extend the maochke's theorem(c.f.[[Block theory]]).

Example:
- The space $F^d$ is an irreducible left module for the complete matrix algebra $Mat_d(F)$ by the natural multiplication.

An algebra is said to be semisimple if and only if $A=\prod_iS_i$ as $A$-module for some simple module $S_i$.

**Definition**
Nonzero $e_1,\cdots,e_k$ in an $F$-algebra $A$ forms a set of orthogonal idempotent if $e_i^2 =e_i$ and $e_ie_j=0$. A idempotent is *primitive* if there is no $e_1,e_2$ such that $e_1+e_2=e$.

**Proporsition**:
Let $A$ be an F-algebra, and $e \in A$ being an independent. Then e is primitive if and only if $Ae$ is indecomposable.

Example:
- Let $H$ be a subgroup of finite group $G$, and $\lambda:H \rightarrow \mathbb{C}^\times$ a representation of $H$ of degree 1. Then $e:=\frac{1}{|H|}\sum_{h \in H}\lambda(x^{-1})x$ is an idempotent in $\mathbb{C}[G]$ (notice that $he=\lambda(h)e$).

---

**Definition**:
suppose that $\lambda=(\lambda_1,\cdots,\lambda_l)\vdash n$ and $\mu=(\mu_1,\cdots,\mu_m) \vdash n$. Then we say $\lambda$ *dominents* $\mu$ wirten $\lambda \trianglerighteq \mu$ if $\lambda_1+\cdots+\lambda_i \geq \mu_1+\cdots+\mu_i$ for all $i \geq 1$. (i.e. $\lambda$ is somehow shorter and fatter in view of Ferrer's diagram than $\mu$).

**Definition**:
If $(A,\leq)$ is a p o set and $b,c \in A$ then we say that $b$ is covered by $c$ or $c$ cover $b$ written $b \prec c$ or $c \succ b$ if $b<c$ and there is no $d \in A$ such that $b<d<c$.  

**Lemma**:(Dominance Lemma)
Let $t,s$ be two tableaux of shape $\lambda,\mu$. If for each index $i$, the element of row $i$ of $s$ are all indifferent column of $t$, then $\lambda \trianglerighteq \mu$.
*Proof*:
By permuting elements in each column of $t$, we may have the element of rows $1,2,\cdots,r$ of $s$ is contained in the row $i_1,\cdots,i_r$ where $i_k \leq k$.
so $\mu_1+\cdots+\mu_i=$ number of elements in the first $i$ rows of $S$ $\leq$ number of elements in the first $i$ rows of $t$ $=$ $\lambda_1+\cdots+\lambda_i$ hence $\lambda \trianglerighteq \mu$.

**Speclit modules**
we now construct all the irreducible modules of $S_n$. These are the so called *Speclit modules*, $S^\lambda$.

**Definition**:
Suppose that $t$ is a $\lambda$-tableaux and $t$ has rows $R_1,\cdots,R_l$ and colimn $C_1,\cdots,C_k$. Then $R_t:=S_{R_1} \times \cdots \times S_{R_l}$ and $C_t:=S_{C_1} \times \cdots \times S_{C_k}$ are the row stablizer and column stablizer of $t$.
In addition, these stablizer are associated with certain elements of $\mathbb{C}[S_n]$. In general, given a subset $H \subseteq \mathbb{C}[S_n]$: $H^+:=\sum_{\pi \in H} \pi \in \mathbb{C}[S_n]$ and $H^-:=\sum_{\pi \in H}sgn(\pi)\pi \in \mathbb{C}[S_n]$. 

$\mathbb{C}[S_n]$ acts on $M^\lambda$ For a tableaux $t$ define $\mathcal{K}_t:=C_t^-=\sum_{\pi \in C_t}sgn(\pi) \pi$. Note that if $t$ has column $C_1,\cdots,C_k$ then $\mathcal{K}_t=\mathcal{K}_{C_1}\cdots\mathcal{K}_{C_k}$.

**Definition**:
If $t$ is a tableaux, then the associated polytableaux if $e_t:=\mathcal{K}\{t\}$.

**Lemma**:
Let $t$ be a tableaux and $\pi \in S_n$. Then 
1. $R_{\pi t}=\pi R_t \pi^{-1}$
2. $C_{\pi t}=\pi C_t \pi^{-1}$
3. $\mathcal{K}_{\pi t}=\pi \mathcal{K}_t \pi^{-1}$
4. $e_{\pi t}=\pi e_t$
*Proof*:
$\sigma \in R_{\pi t} \Longleftrightarrow \sigma\{\pi t\}=\{\pi t\} \Longleftrightarrow \pi^{-1} \sigma \pi\{t\}=\{t\} \Longleftrightarrow \sigma \in \pi R_t \pi^{-1}$.
$e_{\pi t}=\mathcal{K}\{\pi t\}=\pi\mathcal{K}\pi^{-1}\pi\{t\}=\pi\mathcal{K}\{t\}=\pi e_t$.

**Definition**:
For any partition $\lambda$, the corresponding Speclit modules $S^{\lambda}$ is the submodules of $M^\lambda$ spanned by the polytableaux $e_t$ where $t$ is of shape $\lambda$.

**Example**:
- $\lambda=(n) \vdash n$, $e_{1,\cdots,n}=\overline{12\cdots n}$, and $S^{(n)}$ carries the trivial representation for $S_n$. $S^{(n)}$ is a submodule for $M^{(n)}=\mathbb{C}[\overline{12\cdots n}]$ and $S^{(n)}=M^{(n)}$.
- $\lambda=(1^n) \vdash n$, and fix $t=2,\cdots,n$, the column stablizer for and $(1^n)$-tableaux if $S_n$ itself, so $C_t=S_n$ and $\mathcal{K}_t=C_t^-$, so $\mathcal{K}=\sum_{\pi \in S_n} sgn(\pi)\pi$ and $l_t$ is the signed sum of all n! permutation regarded as tableaux. $\forall \pi \in S_n$ then $e_{\pi t}=\pi e_t=\sum_{\sigma \in S_n} sgn(\pi)\pi\sigma\{t\}$.
- $\lambda=(n-1,1) \vdash n$, then each $\lambda$-tableaux is uniquly determined by the elements in the second row. Thus we have a modules isomorphism $M^{(n-1,1)} \simeq \mathbb{C}[1,\cdots,n]$. Using this isomorphism, we may write $(n-1,1)$ tableaux $\{t\}=\overline{\underline{i\cdots j}}$\\$\overline{\underline{k}}=:\overline{\underline{k}}$. This tableaux has corresponding polytableaux $e_t=\overline{\underline{k}}-\overline{\underline{i}}$, and then since $S^{(n-1,1)}$ is cyclic, so $S^{(n-1,1)}=\mathbb{C}[S_n]e_t=\{c_1\overline{\underline{1}}+c_2\overline{\underline{2}}+\cdots+c_n\overline{\underline{n}}:\sum_i c_i=0\}$, hence $dim(S^{(n-1,1)})=n-1$. Let $\mathcal{B}:=\{\overline{\underline{2}}- \overline{\underline{1}},\cdots, \overline{\underline{n}}- \overline{\underline{1}}\}$ be a basis for$S^{(n-1,1)}$. Let $V$ be the $S_n$-module over $\mathbb{C}$ carrying the defining representation for $S_n$, that is $V=\mathbb{C}[1,\cdots,n]$, then $W:=\mathbb{C}[1+\cdots+n]$ is a $S_n$-submodule of $V$. Let $\langle,\rangle$ be an $S_n$-invariant inner product on $V$. Then $W^\perp:=\{v \in V:\langle v,w\rangle,\ \forall w \in W\}$. Let $\chi^{def},\chi^1$ and $\chi^\perp$ be the characters corresponding to $V,W,W^\perp$. Then $V=W \oplus W^\perp$ tells us that $\chi^{def}=\chi^1 + \chi^\perp$. Note that $\chi^{def}=TrX$, where $X_{ij}(\pi)=1$ if $\pi(j)=i$ and $0$ otherwise, so $\chi^{def}(\pi)=\sum_{i=1}^nX_{kk}(\pi)=$ the number of fixed points of $\pi$. Also $\chi^1(\pi)=1, \forall \pi \in S_n$, so we have $\chi^\perp(\pi)=$ the number of fixed points of $\pi$ -1. Let $R:S_n \rightarrow GL_{n-1}(\mathbb{C})$ be the matrix representation corresponding to the module $S^{(n-1,1)}$ commute the action of $S_n$ on $\mathcal{B}$: $\pi(\overline{\underline{l}}- \overline{\underline{1}})=\overline{\underline{\pi(l)}}-\overline{\underline{\pi(1)}}=(\overline{\underline{\pi(l)}}-\overline{\underline{1}})-(\overline{\underline{\pi(1)}}-\overline{\underline{1}})$. $\forall i,j \in \{1,\cdots,n-1\},\ \pi(\overline{\underline{i}}-\overline{\underline{1}})=\sum_k\lambda_k(\overline{\underline{k}}-\overline{\underline{1}})$, and let $R_{ij}(\pi)=1$ if $i=\pi(j)$ and $=-1$ if $\pi(1)=i$ and $=0$ otherwise. So $\chi(\pi)=\sum_kR_{kk}(\pi)=$ number of fixed point of $\pi$ -1. 

Recall: $H^-=\sum_{h \in H}sgn(\pi)\pi$ for any subet $H$ of $S_n$. If $H=\{\pi\}$ then write $\pi^-$ for $H^-$. Note that there is a uniquly determined $S_n$-invariant inner product $\langle,\rangle$ on $M^\lambda$ satisfying $\langle\{t\},\{s\}\rangle=\delta_{\{t\}\{s\}}$.

**Lemma**:(Sign lemma)
Let $H \leq S_n$ be a subgroup
1. If $\pi \in H$, then $\pi H^-=H^-\pi=sgn(\pi)H^-$.
2. $\forall u,v \in M^\lambda$, $\langle H^-u,v\rangle=\langle u,H^-v \rangle$.
3. If the transpesition $(b,c) \in H$, then $H^-=k(\epsilon-(b,c))$ for some $k \in \mathbb{C}[S_n]$.
4. If $t$ is a tableaux in which $b,c$ are in the same row of $t$ and $(b,c) \in H$, then $H^-\{t\}=0$.

**Corollary**:
Let $t$ be a $\lambda$-tableaux and $S$ be a $\mu$-tableaux, where $\lambda,\mu \vdash n$, If $\mathcal{K}_t(\{S\}) \neq 0$, then $\lambda \trianglerighteq \mu$ and if $\lambda=\mu$, then $\mathcal{K}_t(\{S\})= \pm e_t$.
*Proof*:
Let $b,c$ be the elements in the same row of $S$. Suppose that $b,c$ are in the same column of $t$. Then $\mathcal{K}_t=C_t^-=k(\epsilon-(b,c))$ for some $k \in \mathbb{C}[S_n]$. Then part 4 of the Sign lemma tells us that $\mathcal{K}_t\{S\}=0$. Thus $b,c$ must be in different column of $t$. The Dominance lemma tells us that $\lambda \trianglerighteq \mu$. If $\lambda=\mu$, then $\{s\}=\pi \{t\}$ for some $\pi \in C_t$. Since bt the above, if $b,c$ are in the same row of $S$ then they must be in different columns of $t$; and if thet are in the same row of $t$ then they must be in different column of $s$. so $\mathcal{K}_t\{s\}=\mathcal{K}_t\pi\{t\}=C_t^-\pi\{t\}=sgn(\pi)C_t^-\{t\}=sgn(\pi)e_t=\pi e_t$.

**Corollary**:
If $u \in M^\mu$ and $t$ is a $\mu$-tableaux then $\mathcal{K}_tu$ is a multiple of $e_t$.
*Proof*:
Want $u=\sum_iC_i\{s_i\}$, where $\{s_i\}_s$ are $\mu$-tableaux, then the last corollary tells us that $u=\sum_iC_i\mathcal{K}_t\{S_i\}=\sum_iC_i\{s_i\}$

**Theorem**:(Submodule theorem)
LEt $U$ be a submodule of $M^\mu$. Then either $S^\mu \subseteq U$ or $U \subseteq S^{\mu^\perp}$. In particular, if the basis field is $\mathbb{C}$ then speclit modules $S^\mu$ are irreducible.
*Proof*:
Let $v\in U$ and let $t$ be a $\mu$-tableaux then the last corollary tells us that $\mathcal{K}_tv=fe_t$ for some $f \in \mathbb{C}$. 
1. Suppose that there is a $v \in U$ and $\mu$-tableaux $t$ with $f \neq 0$. Because $v \in U$, then we have $fe_t=\mathcal{K}_tv \in U$, so $e_t \in U$, hence $S^\mu \subseteq U$.
2. Suppose that $\forall v \in U$ and $\forall \mu$-tableaux $t$ we have $\mathcal{K}_t v=0$. we clain that $u \subseteq S^{\mu^\perp}$ where $S^{\mu^\perp}=\{u \in M^\mu:\langle u,x \rangle=0 \forall x \in S^\mu\}$. Let $v \in U$ be arbitrary and $t$ be any $\mu$-tableaux. Then 2 of sign lemma we have $\langle v,e_t \rangle=\langle v,\mathcal{K}_t\{t\} \rangle= \langle \mathcal{K}_tv,\{v\} \rangle= \langle 0,\{t\} \rangle=0$. Because the polytableaux $e_t$ spanned $S^\mu$, so $v \in S^{\mu^\perp}$ and $u \subseteq S^{\mu^\perp}$, thus $S^\mu \cap S^{\mu^\perp}=\{0\}$, so $S^\mu$ is irreducible. 

**Proporsition**:
Suppose that the basis field in $\mathbb{C}$ and $\epsilon \in Hom(S^\lambda,M^\mu)$ id nonzero. Then $\lambda \trianglerighteq \mu$, and when $\lambda=\mu$ $\epsilon$ is a multiplication by scalar.
*Proof*:
Because $\epsilon \neq 0$, so there is a polytableaux $e_t$ such that $\epsilon (e_t) \neq 0$. Let $\langle\ ,\ \rangle$ be an $S_n$-invariant inner product on $M^\lambda$ then $M^\lambda=S^\lambda \oplus S^{\lambda^\perp}$ and $\epsilon$ mat be extended to an element in $Hom(M^\lambda,M^\mu)$ by setting $\epsilon(S^{\mu^\perp})=0$. Meanwhile $0 \neq \epsilon(e_t)=\epsilon(\mathcal{K}_t\{t\})=\mathcal{K}_t \epsilon(\{t\})=\mathcal{K}_t(\sum_iC_i\{S_i\})$. The second last corollary tells us that $\lambda \trianglerighteq \mu$. When $\lambda=\mu$, then the last corollary tells us that $\epsilon(e_t)=ce_t$ for some $c\in \mathbb{C}$. $\forall \pi \in S_n$, $\epsilon(e_{\pi t})=\pi(\epsilon e_t)=ce_{\pi t}$. So $\epsilon$ is a multiplication by scalar.

**Theorem**:
The Speclit modules $S^\lambda(\lambda \vdash n)$ form a complete list of pairwise inequivalent irreducible $S_n$-module over $\mathbb{C}$. 
*Proof*:
The $S^\lambda$ are irreducible over $\mathbb{C}$ by the submodule theorem above since $S^\lambda \cap S^{\lambda^\perp}=\{0\}$ over $\mathbb{C}$. Since we have the right number of modules for a full set of pairwise inequivalent irreducible modules, it remains to check that the speclit modules are pairwise inequivalent.
If $S^\lambda \simeq S^\mu$, then there is a nonzero $S_n$-homorphism $\epsilon \in Hom(S^\lambda,M^\mu)$ since $S^\mu \subseteq M^\mu$. Then last proporsition tells us that $\lambda \trianglerighteq \mu$. Similiarli there is a nonzero $S_n$-homorphism $\phi \in Hom(S^\mu,M^\lambda)$ so we have $\mu \trianglerighteq \lambda$ so $\lambda=\mu$, hence $S^\mu \simeq S^\lambda$.
**Remark**:
The Speclit modules are not necessarily irreducible over a field of nonzero characteristic $p$, but $S^\lambda/(S^\lambda \cap S^{\lambda^\perp})$ is irreducible.

**Proporsition**:
Let $G$ be a group. Let $V$ and $W$ be $G$-moduels with $V$ being irreducible with $Hom(V,W)$ be the set of all $G$-moduel homomorphism from $V$ to $W$. Then $dim_{\mathbb{C}}Hom(V,W)$  is the multiplicities of $V$ in $W$.

**Corollary**:
The permulatation module $M^{\mu}$ decomposes as $M^\mu=\bigoplus_{\lambda \trianglerighteq \mu}m_{\lambda\mu}S^{\lambda}$. With the diagonal multiplication $m_{\mu\mu}=1$.
*Proof*:
If $S^\lambda$ appears in $M^\mu$ with nonzero multiplicity $m_{\lambda\mu}$ then $\lambda \trianglerighteq \mu$ bt rhe second last Proporsition. If $\lambda=\mu$ then $m_{\mu\mu}=dimHom(S^\mu,M^\mu)=1$.

**Proporsition**:
Let $H,K$ be subgroups of the finite group $G$, and let $\lambda:H \rightarrow \mathbb{C}^\times$ and $\mu:K \rightarrow \mathbb{C}^\times$ be representations of degree 1. Let $e:=\frac{1}{|H|}\sum_{h \in H} \lambda(h^{-1})h$ and $f:=\frac{1}{|K|}\sum_{k \in K}\mu(k^{-1})k$. If there is a $x \in H \cap K$, with $\lambda(x) \neq \mu(x)$ then $ef=0$.
*Proof*:
Assume that such an $x$ exists, then 
$$ex=\sum_{h \in H}\lambda(h^{-1})hx=\sum_{l \in H}\lambda(xl^{-1})l=\sum_{l \in H} \lambda(x)\lambda(l^{-1})l=\lambda(x)e$$
similiarly, $xf=\sum_{k \in K}=\mu(x)f$.

**Lemma**:
Let $\lambda=(n_1,\cdots,n_k) \geq (m_1,\cdots,m_l)=\mu$ be two partitions of $n$. Let $t$ be a $\lambda$-tableaux $t'$ be a $\mu$-tableaux in $t$ and co-columnar in $t'$. Then $\lambda=\mu$ and $t'=f\delta t$ for some $f \in R_t,\delta \in C_t$.
*Proof*:
The $n_1$ number in tha first row of $t$ all lie in different columns of $t'$. But $t'$ has $m_1$ columns and $\lambda \geq \mu$ so $m_1 \leq n_1$ so $n_1=m_1$. Further, each column of $t'$ contains a unique number from rhe first row of $t$. So applying a suitable column permutation in $C_{t'}$ will takes these $n_1$ numbers into the first row of $\tau_1t'$ for some $\tau_1\in C_{t'}$ such that the numbers in the first row of $\tau_1t'$ are exactly the numbers in the first row of $t$ (in some order). Note $C_{\tau_1t'}=\tau_1C_{t'}\tau_1^{-1}=C_{t'}$. Note since $n_1=m_1$ and $\lambda \geq \mu$, it follows that $n_2 \geq m_2$. The $n_2$ numbers in the second rows of $t$ must all bt in different columns of $\tau_1t'$. BUt $\tau_1t'$ has only $m_2 \leq n_2$, columns which contains cells cout side the first row so $m_2 \geq n_2$ so $m_2=n_2$, and each of these $m_2$ contains a unique element in the second row of $t$. Applying a suitable column permutation $\tau_2 \in C_{\tau_1t'}=C_{t'}$ shift these $n_2=m_2$ numbers into the second row of $\tau_2\tau_1t'$. Now $\tau_2\tau_1t'$ has the same numbers in the first row as $t$ has in its first row, and $\tau_1\tau_2t'$ has tha same numbers in the second ros as $t$ has its second row. And still the 2 numbers columnar in $t$ and re co-columnar in $\tau_2\tau_1t'$. Covering the first 2 column and repeating the argument, and conting on in these way e find that $m_i=n_i,\forall i \in \{1,\cdots,k\}$, and there exists a permutation $\tau=\tau_k\tau_{k-1}\cdots\tau_1$ such that $\tau t'$ has the same number in it $i$-th as $t$ has in the $i$-th row so $\exists f \in R_t$ such that $ft=\tau t'$. Then $\tau^{-1} \in C_{\tau t'}=C_{ft}=fC_t=f^{-1}$. So if we put $\delta:=f^{-1}\tau^{-1}f$ then $\delta \in C_t$. Furthermore, $f\delta t=ff^{-1}\tau^{-1}(ft)=t'$.

**Definition**:
Let $\lambda \vdash n$ and $t$ be a $\lambda$-tableaux $e(t):=R_t^{+}C_t^- \in \mathbb{C}[S_n]$.

It will tremepine then $e(t)$ is a scalar multiple of a primitive idempotent in $\mathbb{C}[S_n]$ and consequently $\mathbb{C}[S_n]e(t)$ is a minimal left ideal in $\mathbb{S_n}$. Let $\lambda,\mu \vdash n$ and let $t$ be a $\lambda$-tableaux and $t'$ be a $\mu$-tableaux $e(t)\mathbb{C}[S_n]e(t')=\{e(t)ae(t'):a \in \mathbb{C}[S_n]\}$ it is a vector subspace of $\mathbb{C}[S_n]$. Suppose that $\lambda>\mu$, and let $\tau \in S_n$ be arbitrary. By the last lemma, there is number $i,j$ collinear in $t$ and co-columnar in $\tau t'$. So $(i,j) \in R_t \cap C_{\tau t'}$. $R_t^{+}(i,j)=\sum_{\delta \in R_t}\delta(i,j)\sum_{f \in R_t \in R_t}f=R_t^+$. Similiarly $(i,j)C_{\tau t'}^-=\sum_{\delta \in C_{\tau t'}}sgn(\delta)(i,j)\delta=\sum_{f \in C_{\tau t'}}-sgn(f)f=-C_{\tau t'}^-$. So $R^+_tC_{\tau t'}^-=(R_t^+(i,j))C_{\tau t'}^-=-R_{t}^+C_{\tau t'}^-=0$ for all $\tau \in S_n$. Hence $R_t^+\tau C_t^-\tau=0$, if $a=\sum_{\tau \in S_n}a_\tau \tau$, then $R_t^+aC_{t'}^-=0$, and $e(t)be(t')=0$. Similiarly if $\mu >\lambda$, then $_t^-R_{\tau t'}^+=0,\forall \tau \in S_n$, and $e(t)be(t')=R_t^+(_t^-bR_t^+)C_t^-$=0.

**Proporsition**:
Laet $\lambda,\mu \vdash n$ and let $t$ be $\lambda$-tableaux and $t'$ be $\mu$-tableaux if $\lambda \neq \mu$ then $e(t)\mathbb{C}[S_n]e(t')=0$.

**Recall**
$\lambda,\mu \vdash n$ and $\lambda \geq \mu$, and $t$ a $\lambda$-tableaux $t'$ a $\mu$-tableaux. Suppose that noe two numbers are collinear in $t$ which co-columnar in $t'$. Then $\lambda=\mu$ abd $t'=f\delta t$ for $f \in R_t,\delta \in C_t$. $\lambda \vdash n$, $t$ a $\lambda$-tableaux $e(t):=R_t^+C_t^- \in \mathbb{C[S_n]}$, and $e(t)\mathbb{C}[S_n]e(t')=\{e(t)ae(t'):c \in \mathbb{C}[S_n]\}$.

**Proporsition**:
$\lambda,\mu \vdash n$, and $t$ a $\lambda$-tableaux and $t'$ a $\mu$-tableaux. If $\lambda \neq \mu$, then $e(t)\mathbb{C}[S_n]e(t')=\{0\}$.

Let $\lambda \vdash n$, and $t$ a $\lambda$-tableaux and $\tau \in S_n$, If there is two number $i,j$ which are collinear in $t$ and co-columnar in $\tau t$, then $(i,j) \in R_t \cap C_{\tau t}$, $R^+_t(i,j)=\sum_{\delta \in R_t}(\delta(i,j))=\sum_{\pi \in R_t}=R_t^+$. $(i,j)C_{\tau t}^-=\sum_{\delta \in C_{\tau t}}(i,j)sgn(\delta)\delta=-\sum_{\delta}sgn(i,j)sgn(\delta)(i,j)\delta=-\sum_{\pi \in C_{\tau t}}sgn(\pi)\pi=-C_{\tau t}^-$. Hence $R_t^+C_{\tau t}^-=-R^+_tC_{\tau t}^-$. If there are numbers $i,j$ which are collinear in $t$ and co-columnar in $\tau t$, then the lemma above tells us that $\tau t=f \delta t$ so $\tau=f \delta$. Thus, if $R_t^+\tau C_t^- \neq 0$, then for some $f \in R_t$ and $\delta \in C_t$ we have $R_t^+\tau C_t^-=R_t^+f\delta C_t^-=(R_t^+f)(\delta C_t^-)=R^+sgn(\delta)C_t^-=sgn(\delta)e(t)$. $R_t^+ \tau C_t^-$ is a scalar multiple of $e(t)$ for all $\tau \in S_n$ and $\lambda_\tau \in \mathbb{C}$.
Thus if $a =\sum_{\tau \in S_n}\lambda_\tau\tau$, then $R_t^+aC_t^-=\sum_{\tau}\lambda_-\tau R_t^+\tau C_t^-$ is a scalar multiple of $e(t)$. For all $b \in \mathbb{C}[S_n]$, $e(t)be(t)=R_t^+C_t^-bR_t^+C_t^-=\lambda e(t)$ for some $\lambda$. Hence $e(t)\mathbb{C}[S_n]e(t)$ are either $\{0\}$ or $\mathbb{C}e(t)$.

**Proporsition**:
Let $\lambda \vdash n$, and $t$ be a $\lambda$-tableaux. Then $e(t)^2$ is a nonzero scalar multiple of $e(t)$.
*Proof*:
First take $b=1$, we know $e(t)^2=\lambda e(t)$. It remains to show that $\lambda \neq 0$. Note that $f,\delta$ are unique, so $e(t)=\sum_{f \in R_t}\sum_{\delta \in G}sgn(\delta)f\delta$ all the summands are distinct. If we write $e(t)=\sum_{\tau \in S_n}\alpha_\tau \tau$ then $\alpha_{1_{S_n}}=1$.
Our strategy: to compute in 2 ways the trace of the linear map of $f:\mathbb{C}[S_n] \rightarrow \mathbb{C}[S_n]$ given by the right multiplication of $e(t)$.
Using the standrad basis for $\mathbb{C}[S_n]$ consisting of all elements of $S_n$. If $\delta \in S_n$ arbitrary, then $f(z)=\delta e(t)=\sum_{\tau \in S_n}\alpha_\tau \delta \tau=\sum_\tau\alpha_{\delta^{-1}\tau}\tau$ and the coefficnet of $\delta$ in the sum is $\alpha_{1_{S_n}}=1$. Thus when computing the matrix of $f$ relative to the basis of $\mathbb{C}[S_n]$, all the diagonal structures are 1, so the trace $f=dim(\mathbb{C}[S_n])=n!$. Because $\mathbb{C}[S_n]e(t)$ is a vector subspace of $\mathbb{C}[S_n]$, so we can shoose a basis for if, and extend it to a basis for $\mathbb{C}[S_n]$. For $1 \leq i \leq d$, $a_i=b_ie(t)$, and because $e(t)^2=\lambda e(t)$, we have $f(a_i)=\lambda a_i$. So the first columns of the matrix of $f$ relative to the basis $a_1,\cdots,a_d,a_{d+1},\cdots,a_{n!}$. For $i>d$, $f(a_i)=a_ie(t)$, and so $f(a_i)$ is a linear combation of $a_1,\cdots,a_d$ only. In particular, the coefficnet for $a_i$ is zero when $i>d$. So the trace of $f=d\lambda$, so $d\lambda=n! \neq 0$.

With all the alone notation s define $E_t:=\frac{1}{\lambda}e(t)$.
Then $E_t$ i an indemopotent, since $E_t^2=E_t$.

It turnso out that $E_t$ is a primitive idempotent in $\mathbb{C}[S_n]$ and hence that left ideal $\mathbb{C}S_nE_t$ of $\mathbb{C}[S_n]$ is an indecomposable $\mathbb{C}[S_n]$A$-module.

**Theorem**:
Let $\lambda \vdash n$ and let $t$ be a $\lambda$-tableaux. Then the left idela $\mathbb{C}[S_n]E_t$ of $\mathbb{C}[S_n]$ is an irreducible left $\mathbb{C}[S_n]$-module.
Further, two such submodules $\mathbb{C}[S_n]E_s$ and $\mathbb{C}S_nE_{S'}$ are isomorphic iff $S,S'$ are tableaux of the same shape.
Moreover, choosing all tableaux for each partition of $n$, we obtain a full set of pairwise inequivalent irreducible left $\mathbb{C}[S_n]$-module.

# Representation for reflection group
let $V$ be a vector space over $\mathbb{R}$ and let $(,)$ be a symmetric bilinear form on $V$. 

**Definition**:
1. The isetrepic set $Q:=\{x \in V:(x,x)=0\}$ for $(V,(,))$.
2. The radical $Rad:=\{x \in V:(x,y)=0,\forall y \in V\}$ for $(V,(,))$.

**Question**: (V,(,)) is Euchdean then $Rad=\{0\}$ is the converse true?

**Definition**:
A linear transformation $f:V \rightarrow V$ is orthogonal if it is bijective and $(f(x),f(y))=(x,y)$. The set of all orthogonal transformation of $(V,(,))$ is a group $O(V) \leq GL(v)$, a reflection $f:V \rightarrow V$ is an orthogonal transformation of order 2 whose -1-eigenspace is 1-dim and not contained in the radical. Let $x \in V$ arbitrary, then $f(f(x)-x)=x-f(x)$, so $f(x)-x$ is contained in the -1-eigenspace. We can then write $f(x)=x+\lambda_xa$ for some $\lambda_x \in \mathbb{R}$. Using the fact that $f$ is orthogonal, we have $(a,x)=(f(a),f(x))=(-a,x+\lambda_x+a)$, so $\lambda_x=-2\frac{(a,x)}{(a,a)}$, hence $f(x)=x-2\frac{(a,x)}{(a,a)}a$. Conversely, if $a \in V$ nonisotropic i.e. $(a,a) \neq 0$. Let $f:V \rightarrow V$ be defined by $f(x)=x-2\frac{(a,x)}{(a,a)}a$. Then $f(a)=-1$, and $f^2(x)=x$. One can also easily check that $(f(x),f(y))=(x,y)$, and the -1-eigenspace is not contained in Rad.

**Definition**:
FOr nonisotropic $a$ in $V$, $f_a=f \in O(V)$ defined by $f(x)=x-2\frac{(a,x)}{(a,a)}a$ is the reflection corresponding to $a$.

**Lemma**:
Let $w \in O(V)$ and $a \in (V,(,))$ nonisotropic. Then $wf_aw^{-1}=f_{wa}$.
*Proof*:
We have $(wa,wa) \neq 0$, and $wa$ is nonisotropic, and $f_{wa}$ makes sense. For all $x \in V$, $wf_aw^{-1}=w(w^{-1}x-2\frac{(w^{-1}x,a)}{(a,a)}a)=x-2\frac{(x,wa)}{(wa,wa)}wa=f_{wa}x$.

Thus $O(V)$ acts on the set $\{f_a:(a,a) \neq 0\}$ by permutation of the reflections

**Definition**:
FOr nonisotropic $a \in V$ then set $\{x:f_ax=x\}=\{x \in V:(x,a)=0\}$. The set of fixed points of $f_a$ i=s called the mirror of $f_a$.

Q:If $V$ is euclidean, the mirror of $f_a$ is a hyprplane (subspace of codimension 1 in $V$) Is the mirror of $f_a$ still a hyprplane if $V$ is not euclidean.

If $V$ is euclidean, then $f_af_b$ is a rotation(clockwise) through $\theta$. In particular, if $\theta=\frac{\pi}{n}$, then $f_af_b$ is of order $n$.

$a \in V$ nonisotropic, and let $\lambda \in \mathbb{R}-\{0\}$, then $f_{\lambda a}x=x-2\frac{(x,\lambda a)}{(\lambda a , \lambda a}\lambda a=x-2\frac{(x,a)}{(a,a)}a=f_ax$. So $f_a=f_{-a}$ we can arrange $a$ and $b$ so that the angle between $a,b$ is greater than $\frac{\pi}{2}$.

**Proporsition**:
Suppose that $a,b \in V$ with $(a,a)=(b,b)=1$ and $(a,b)=-\cos\theta$ where $\theta=\frac{\pi}{n}$ then 
1. $(f_af_b)^ia=\frac{\sin(2i+1)\theta}{\sin\theta}a+\frac{\sin(2i\theta)}{\sin\theta}b$.
2. $f_a,f_b$ has order $n$.

Let $\langle f_a,f_b \rangle$ denote the subgroup of $O(V)$ generated by $f_a,f_b$, if $(a,a)=(b,b)=1$ and $(a,b)=-\cos\frac{\pi}{n}$ then it is the dihedral group of order $2n$.

General fact:
any group generated by the elements of order $2$ is dihedral. $D:=\langle r,s \rangle$, then group generated by $r$ and $s$ where $r^2=s^2=1$ and $(rs)^n=1$, the only elements in $D$ is alternating prodcut of $r$ and $s$. Identifying even numbers of factors are power of $f_a,f_b$ and hence are rotations and there are $n$ of these. If $w \in D$, then $f_{wa}=wf_aw^{-1} \in D$ and $f_{wb} \in D$. Then we have $a_i=(f_af_b)^ia$, $f_{a_i} \in D$. The coefficnet of $a$ and $b$ in $a_i$ $0 \leq i \leq \frac{n-1}{2}$ and $b_i$ $1 \leq i \leq \frac{n}{2}$ are greater than 0, and these elements together ith the $n$ rotation make up all the elements of $D$. The larger the n in the above, the clear of $(a,b)$ to $-1$ note that $(a,b)>-1$ when ever $a$ and $b$ are linearly independent and $V$ euclidean. But we do not want to stay in the euclidean setup.

**Proporsition**:
$a,b \in V$ $(a,a)=(b,b)=1$ and $(a,b)=-t \leq -1$ put $\theta:=ln(t+\sqrt{t^2-1})$ i.e. $t=\cosh\theta$ then
1. $(f_a,f_b)^ia=\frac{\sinh(2i+1)\theta}{\sinh\theta}a+\frac{\sinh(2i)\theta}{\sinh\theta}b$.
2. $\langle f_a,f_b \rangle$ has infinent order

**Definition**:
Let $V$ be a vector space/$\mathbb{R}$ and $(,)$ be a symmetric bilinear form on $V$, a reflection group on $V$ generated by reflection $f_a$ corresponding to nonisotropic vectors $a$ in $V$.

**Definition**:
A pair $(W,R)$ is called a coxeta system with paramenters, $\{m_{st} \in \mathbb{N}_{\geq 1} \cup \{\infty\}:s,t \in R\}$, if $W$ is an abstract group generated by elements of $R$ subject only the relation
1. $1 \not \in R$ and $s^2=1$ for all $s \in R$.
2. $(st)^{m_{st}}=1$ for all $s,t \in R$.
In the case that $m_{st}=\infty$ then there is no relation between $s$ and $t$; and $m_{st}=1$ iff $s=t$.

**Definition**:
$\Delta=(V,\Pi,(,))$  is called a coveter datumn of a coxeter system $(W,R)$ if 
1. $V$ is a vector space over $\mathbb{R}$.
2. $(,)$ is a symmetric bilinear form on $V$.
3. $\Pi:=\{\alpha_s:s \in R\}$ called a rotation basis or a set of simple roats, if a set of vectors in $V$ in bijective correspondence with $R$ such that $(\alpha_s,\alpha_s)=1$ and $(\alpha_s,\alpha_t)=\begin{cases}-\cos\frac{\pi}{m_{st}} \  &\text{if } m_{st}<\infty\\ r_{st} &\text{if } m_{st}=\infty \end{cases}$ and $0 \not\in \mathbb{R}_{\geq 0}\Pi:=\{\sum_{a}\lambda_aa:\lambda_a \in \mathbb{R}_{\geq 0},\ \exists\lambda_a \neq 0\}$. If $(V,(,))$ is euclidean, then $\Pi$ is linearly independent.

**Definition**:
Let $\Delta$ be a coxeter datumn for coxeter system $(W,R)$ set $R_{ref}:=\{f_{\alpha r}:r \in R\}$ and $W_{ref}:=\lvert R_{ref}\rvert \subset O(V) \subset GL(V)$.

WTS there is a unique isomorphism $f_{Tits}:W \rightarrow W_{ref}$ sending $s \mapsto f_{\alpha s}$ once this is done, we say that $W_{ref}$ bears the standard Tits representation of $W$ on $V$.
It tells us that the order of $f_{\alpha s}f_{\alpha_t}$ is $m_{st}$.

**Definition**:
Given a coxeter system $(W,R)$ let $l:W \rightarrow \mathbb{N}$ be the length fuction of $(W,R)$ given by $l(w):=\min\{n \in \mathbb{N}:w=r_1 \cdots r_n\ ,r_i \in R\}=\min\{n \in \mathbb{N}:w \in R^n\}$. If $w=r_1\cdots r_n \in R^n$ and $l(w)=n$ then $r_1\cdots r_n$ is called a reduced expression for $w$.

**Lemma**:
1. $\forall w_1,w_2 \in W$, $l(w_1w_2) \leq l(w_1)+l(w_2)$.
2. $\forall w \in W$, $l(w)=l(w^{-1})$.
3. $l(w)=0$ iff $w=1$.
4. If $w \neq 1$, then there is a $s \in R$ with $l(sw)=l(w)-1$.

**Theorem**(Tits):
Let $w \in W$, $r \in R$ If $l(wr) \geq l(w)$ then $w\alpha_r \in \mathbb{R}_{\geq 0}\Pi$.

**Corollary**:
The homomorphism $f_{Tits}$ is an isomorphism.
*Proof*:
Provided by the above theorem. Let $w \in ker(f_{Tits})$. Then $w\alpha_s=\alpha_s$ for all $s \in R$. If $l(w) \neq 0$, then there is $s \in R$, $l(ws)=l(w)-1$  and $w':=ws$, so $l(ws) \geq l(w')$. The theorem tells that $w'\alpha_s \in \mathbb{R}_{\geq 0}\Pi$ Then $\alpha_s=w\alpha_s=w's\alpha_s=w'f_{\alpha_s}\alpha_s=-w'\alpha_s$, so $0=\alpha_s=w'\alpha_s \in \mathbb{R}_{>0}\Pi$ cotradicting $0 \not\in \mathbb{R}_{>0}\Pi$.

*Proof of the theorem*:
Bt contradiction. Let $w \in W$ of minimal length that the statement failed and $\exists r \in R$ with $l(wr) \geq l(w)$, but $w\alpha_r \not\in RLC(\pi)$. $w \neq 1$, for $1\alpha_r=\alpha_r \in PLC(\pi)$. THus $l(w) \geq 1$, and we may choose $s \in R$, withh $l(ws)=l(w)-1$, $w_1:=ws$. If $l(w_1r) \geq l(w_1)$, then stop and note that $l(w_1t) \geq l(w_1)$ for $t=r$ and $t=s$. If $l(w_1r)<l(w_1)$, wew set $w_2:=w_1r$. Note $l(w_2)=l(w_1)-1=l(w)-2$. If not the stop.
Otherwise continue to construct a sequence $w_0=2,w_1,\cdots,w_k$ with $l(w_i)=l(w)-i$. When $i<k$, $w_{i+1}=\begin{cases}w_ir \qquad \text{if i is odd}\\ w_is \qquad \text{if i is even} \end{cases}$. Note $0 \leq l(w_k)=l(w)-k$, so $l(w)$ is the upper bound for the possible value of $k$.Choose $k$ as large as possible, then $l(w_kt) \geq l(w_k)$ for $t=r$ or $t=s$, for otherwise we cam construct $w_{k+1}$. 
Now the minimality of $l(w)$ in the original counter example => $w_k\alpha_r \in PLC(\pi)$. Note $w=w_kv$, where $v$ is a alternating product of $r$ and $s$, ending in $s$ and $v$ has $k$ factors => $l(v) \leq k$. But $w=w_kv$, so $l(w) \leq l(w_k)+l(v)$, hence $l(w)=k$. Further our original assumpotion $l(wr) \geq l(w)$, then $l(w_k)+l(vr) \geq l(wr) \geq l(w) = l(w_k)+l(v)$, so $l(vr)\geq l(v)$. So connot hace a reduced expression endding with $r$, for other wise $l(vr)<l(v)$. Let $m=m_{re}$, if $m=\infty$, then $l(v)=k<m$, if $m$ is finite, since $V$ cannot have a reduced expression ending in $r$, so $v$ is not the largest element in the dihedral group $\langle r,s \rangle$ of order $2m$, so $l(v)<m$.
The matrix of $(rs)^i$ on theis subspace with order basis $\{\alpha_r,\alpha_s\}$ is $\begin{pmatrix}t_{2i+1}&-t_{2i}\\ t_{2_i}&-t_{2i-1}\end{pmatrix}$, where $t_i=\frac{\sin(i\theta)}{\sin\theta}$, $\theta=\frac{\pi}{m}$ if $m<\infty$, and $t_i=\frac{\sinh i\theta}{\sinh\theta}$, $\theta=cosh^{-1}(-\alpha_r,\alpha_s)$ if $m=\infty$. $t_i \geq 0$ for all $i$.
If $k=2i$ even $v\alpha_r=(rs)^j\alpha_r=t_{2j+1}\alpha_r+t_{2j}\alpha_s$. If $t=2j$ odd, then $v\alpha_r=(sr)^js\alpha_r=t_k\alpha_r+t_{k+1}\alpha_r$. So the coefficnet of $\alpha_r$ and $\alpha_s$ in $v\alpha_r$ are $t_k$ and $t_{k+1}$ in one way or another. $t_k \geq 0$, $t_{k+1} \geq 0$ since $k<m=m_s$, so $v\alpha_r=\lambda\alpha_r+\mu\alpha_s$ for $\lambda \geq 0,\ \mu \geq 0$, so $w\alpha_r=w_kv\alpha_r=w_k(\lambda\alpha_r+\mu\alpha_s)=\lambda w_k\alpha_r+\mu w_k\alpha_s \in PLC(\pi)$.

## Diagranmetic description of $\pi$ 
Draw a greph that has vertex set equal to $\pi$ and join the vertices corresponding to $\alpha_s$ and $\alpha_t$ in $\pi$ by an edge labelled $m_{st}$ if $m_{st}>2$. The lable $m_{st}=3$ is ommitted. 
If a root basis $\pi$ can be split ito to new empty distict diagromomatic subsets $\pi_1$ and $\pi_2$. Then the diagram for $\pi$ will be disconnected, it will commits of the diagrams for $\pi_1$ alongside the diagram for $\pi_2$. If $\alpha_r \in \pi_1$, $\alpha_s \in \pi_2$, $(\alpha_r,\alpha_s)=0$ and $m_{rs}=2$, the $(rs)^2=1$ <=> $rs=sr$. $w=w_1 \times w_2$ reducible, then $w_{\pi_2}=\langle s:\alpha_s \in \pi_2 \rangle$, $w_{\pi_2}=\langle r:\alpha_r \in \pi_1 \rangle$. If the diagram for $\pi$ cannot bt splitted into 2 distinct parts there $W$ is called irreducible.(not all correct)